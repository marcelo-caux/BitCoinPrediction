{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-702aa240876f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#================== gist_1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import initializers\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n",
    "#================== gist_2\n",
    "\n",
    "#data = pd.read_csv('../input/bitstampUSD_1-min_data_2012-01-01_to_2017-10-20.csv')\n",
    "#data = pd.read_csv('/home/UFF/IA/Trabalho/Dados/bitstampUSD_1-min_data_2012-01-01_to_2018-06-27.csv')\n",
    "data = pd.read_csv('/home/UFF/IA/Trabalho/Dados/Exp10diasVlLow.csv')\n",
    "data.isnull().values.any()\n",
    "\n",
    "#================== gist_3\n",
    "\n",
    "data.head(10)\n",
    "\n",
    "\n",
    "#================== gist_4\n",
    "\n",
    "#data['date'] = pd.to_datetime(data['Timestamp'],unit='s').dt.date\n",
    "#group = data.groupby('date')\n",
    "#Daily_Price = group['Weighted_Price'].mean()\n",
    "group = data.groupby('DataHora')\n",
    "Daily_Price = group['VlLow'].mean()\n",
    "Daily_Price.head()\n",
    "\n",
    "#================== gist_5\n",
    "\n",
    "Daily_Price.tail()\n",
    "\n",
    "#================== gist_6\n",
    "\n",
    "#from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "#---- nota: delta.days devolve a diferença em dias excluindo o último dia... 9-1=8 (obvio)\n",
    "#d0 = date(2016, 1, 1)\n",
    "#d1 = date(2017, 10, 15)\n",
    "d0 = datetime(2018, 6, 1, 0, 0, 0) #para extender a 100 dias, usar 2018-03-03\n",
    "d1 = datetime(2018, 6, 7, 23, 59, 0)\n",
    "delta = d1 - d0\n",
    "#days_look = delta.days + 1\n",
    "days_look = int((delta.days+1)*((delta.seconds/60) + 1))\n",
    "print(days_look)\n",
    "\n",
    "#d0 = date(2017, 8, 21)\n",
    "#d1 = date(2017, 10, 20)\n",
    "d0 = datetime(2018, 6, 8, 0, 0, 0) #para 10 dias de treinamento , usar 2018-06-02\n",
    "d1 = datetime(2018, 6, 9, 23, 59, 0)\n",
    "delta = d1 - d0\n",
    "#days_from_train = delta.days + 1\n",
    "days_from_train = int((delta.days+1)*((delta.seconds/60) + 1))\n",
    "print(days_from_train)\n",
    "\n",
    "#d0 = date(2017, 10, 15)\n",
    "#d1 = date(2017, 10, 20)\n",
    "d0 = datetime(2018, 6, 9, 0, 0, 0)\n",
    "d1 = datetime(2018, 6, 9, 23, 59, 0)\n",
    "delta = d1 - d0\n",
    "#days_from_end = delta.days + 1\n",
    "days_from_end = int((delta.days+1)*((delta.seconds/60) + 1))\n",
    "print(days_from_end)\n",
    "\n",
    "#================== gist_7\n",
    "\n",
    "df_train= Daily_Price[len(Daily_Price)-days_look-days_from_end:len(Daily_Price)-days_from_train]\n",
    "df_test= Daily_Price[len(Daily_Price)-days_from_train:]\n",
    "\n",
    "print(len(df_train), len(df_test))\n",
    "\n",
    "#================== gist_8\n",
    "\n",
    "working_data = [df_train, df_test]\n",
    "working_data = pd.concat(working_data)\n",
    "\n",
    "working_data = working_data.reset_index()\n",
    "#working_data['date'] = pd.to_datetime(working_data['date'])\n",
    "#working_data = working_data.set_index('date')\n",
    "working_data['DataHora'] = pd.to_datetime(working_data['DataHora'])\n",
    "working_data = working_data.set_index('DataHora')\n",
    "\n",
    "#================== gist_9-10\n",
    "\n",
    "#s = sm.tsa.seasonal_decompose(working_data.Weighted_Price.values, freq=60)\n",
    "s = sm.tsa.seasonal_decompose(working_data.VlLow.values, freq=1440)\n",
    "\n",
    "trace1 = go.Scatter(x = np.arange(0, len(s.trend), 1),y = s.trend,mode = 'lines',name = 'Trend',\n",
    "    line = dict(color = ('rgb(244, 146, 65)'), width = 4))\n",
    "trace2 = go.Scatter(x = np.arange(0, len(s.seasonal), 1),y = s.seasonal,mode = 'lines',name = 'Seasonal',\n",
    "    line = dict(color = ('rgb(66, 244, 155)'), width = 2))\n",
    "\n",
    "trace3 = go.Scatter(x = np.arange(0, len(s.resid), 1),y = s.resid,mode = 'lines',name = 'Residual',\n",
    "    line = dict(color = ('rgb(209, 244, 66)'), width = 2))\n",
    "\n",
    "trace4 = go.Scatter(x = np.arange(0, len(s.observed), 1),y = s.observed,mode = 'lines',name = 'Observed',\n",
    "    line = dict(color = ('rgb(66, 134, 244)'), width = 2))\n",
    "\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = dict(title = 'Seasonal decomposition', xaxis = dict(title = 'Time'), yaxis = dict(title = 'Price, USD'))\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='seasonal_decomposition')\n",
    "\n",
    "#================== gist_11\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "ax = plt.subplot(211)\n",
    "#sm.graphics.tsa.plot_acf(working_data.Weighted_Price.values.squeeze(), lags=48, ax=ax)\n",
    "sm.graphics.tsa.plot_acf(working_data.VlLow.values.squeeze(), lags=48, ax=ax)\n",
    "ax = plt.subplot(212)\n",
    "#sm.graphics.tsa.plot_pacf(working_data.Weighted_Price.values.squeeze(), lags=48, ax=ax)\n",
    "sm.graphics.tsa.plot_pacf(working_data.VlLow.values.squeeze(), lags=48, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#================== gist_12\n",
    "\n",
    "#df_train = working_data[:-60]\n",
    "#df_test = working_data[-60:]\n",
    "df_train = working_data[:-2880]\n",
    "df_test = working_data[-2880:]\n",
    "\n",
    "#================== gist_13\n",
    "\n",
    "def create_lookback(dataset, look_back=2): #valor original=1 (dia), agora 1/2 dia = 720 min...\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "#================== gist_14\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "training_set = df_train.values\n",
    "training_set = np.reshape(training_set, (len(training_set), 1))\n",
    "test_set = df_test.values\n",
    "test_set = np.reshape(test_set, (len(test_set), 1))\n",
    "\n",
    "#scale datasets\n",
    "scaler = MinMaxScaler()\n",
    "training_set = scaler.fit_transform(training_set)\n",
    "test_set = scaler.transform(test_set)\n",
    "\n",
    "# create datasets which are suitable for time series forecasting\n",
    "look_back = 1\n",
    "X_train, Y_train = create_lookback(training_set, look_back)\n",
    "X_test, Y_test = create_lookback(test_set, look_back)\n",
    "\n",
    " # reshape datasets so that they will be ok for the requirements of the LSTM model in Keras\n",
    "X_train = np.reshape(X_train, (len(X_train), 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (len(X_test), 1, X_test.shape[1]))\n",
    "\n",
    "#================== gist_15\n",
    "\n",
    "# initialize sequential model, add 2 stacked LSTM layers and densely connected output neuron\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile and fit the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model.fit(X_train, Y_train, epochs=100, batch_size=16, shuffle=False,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    callbacks = [EarlyStopping(monitor='val_loss', min_delta=5e-5, patience=20, verbose=1)])\n",
    "\n",
    "#================== gist_16\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = np.arange(0, len(history.history['loss']), 1),\n",
    "    y = history.history['loss'],\n",
    "    mode = 'lines',\n",
    "    name = 'Train loss',\n",
    "    line = dict(color=('rgb(66, 244, 155)'), width=2, dash='dash')\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = np.arange(0, len(history.history['val_loss']), 1),\n",
    "    y = history.history['val_loss'],\n",
    "    mode = 'lines',\n",
    "    name = 'Test loss',\n",
    "    line = dict(color=('rgb(244, 146, 65)'), width=2)\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = dict(title = 'Train and Test Loss during training',\n",
    "              xaxis = dict(title = 'Epoch number'), yaxis = dict(title = 'Loss'))\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='training_process')\n",
    "\n",
    "#================== gist_17\n",
    "\n",
    "# add one additional data point to align shapes of the predictions and true labels\n",
    "X_test = np.append(X_test, scaler.transform(working_data.iloc[-1][0].reshape(-1, 1)))\n",
    "X_test = np.reshape(X_test, (len(X_test), 1, 1))\n",
    "\n",
    "# get predictions and then make some transformations to be able to calculate RMSE properly in USD\n",
    "prediction = model.predict(X_test)\n",
    "prediction_inverse = scaler.inverse_transform(prediction.reshape(-1, 1))\n",
    "Y_test_inverse = scaler.inverse_transform(Y_test.reshape(-1, 1))\n",
    "prediction2_inverse = np.array(prediction_inverse[:,0][1:])\n",
    "Y_test2_inverse = np.array(Y_test_inverse[:,0])\n",
    "\n",
    "#================== gist_18\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = np.arange(0, len(prediction2_inverse), 1),\n",
    "    y = prediction2_inverse,\n",
    "    mode = 'lines',\n",
    "    name = 'Predicted labels',\n",
    "    line = dict(color=('rgb(244, 146, 65)'), width=2)\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = np.arange(0, len(Y_test2_inverse), 1),\n",
    "    y = Y_test2_inverse,\n",
    "    mode = 'lines',\n",
    "    name = 'True labels',\n",
    "    line = dict(color=('rgb(66, 244, 155)'), width=2)\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted',\n",
    "             xaxis = dict(title = 'Minute number'), yaxis = dict(title = 'Price, USD')) # valor original de title  = 'Day number'\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='results_demonstrating0')\n",
    "\n",
    "#================== gist_19\n",
    "\n",
    "RMSE = sqrt(mean_squared_error(Y_test2_inverse, prediction2_inverse))\n",
    "print('Test RMSE: %.3f' % RMSE)\n",
    "\n",
    "#================== gist_20\n",
    "\n",
    "Test_Dates = Daily_Price[len(Daily_Price)-days_from_train:].index\n",
    "\n",
    "trace1 = go.Scatter(x=Test_Dates, y=Y_test2_inverse, name= 'Actual Price',\n",
    "                   line = dict(color = ('rgb(66, 244, 155)'),width = 2))\n",
    "trace2 = go.Scatter(x=Test_Dates, y=prediction2_inverse, name= 'Predicted Price',\n",
    "                   line = dict(color = ('rgb(244, 146, 65)'),width = 2))\n",
    "data = [trace1, trace2]\n",
    "layout = dict(title = 'Comparison of true prices (on the test dataset) with prices our model predicted, by dates',\n",
    "             xaxis = dict(title = 'DataHora'), yaxis = dict(title = 'Price, USD')) # original title = 'Date'\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='results_demonstrating1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
